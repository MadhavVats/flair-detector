{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     flairs                                             titles  upvotes  \\\n",
      "0  AskIndia  Need feedback for Insurance Policy that I took...        1   \n",
      "1  AskIndia   Somebody want to kill my full family what to do?       94   \n",
      "2  AskIndia  Ambassador of India takes back my newly issued...       13   \n",
      "3  AskIndia             [AskIndia] Cingari, Cengar or Tzengar?        0   \n",
      "4  AskIndia  Recommendations for books on Indian history wr...       16   \n",
      "\n",
      "       id                                                url  num_comms  \\\n",
      "0  1s57oi  https://www.reddit.com/r/india/comments/1s57oi...          1   \n",
      "1  b7pvwt  https://www.reddit.com/r/india/comments/b7pvwt...         24   \n",
      "2  bdfid1  https://www.reddit.com/r/india/comments/bdfid1...         27   \n",
      "3  18ntue  https://www.reddit.com/r/india/comments/18ntue...          0   \n",
      "4  avt1qx  https://www.reddit.com/r/india/comments/avt1qx...          9   \n",
      "\n",
      "        created                                            content  \\\n",
      "0  1.386254e+09  **Re-posting here because of lack of activity ...   \n",
      "1  1.554080e+09  It's now 24hrs, But local police station is no...   \n",
      "2  1.555361e+09  Hello /AskIndia!  First time poster, long time...   \n",
      "3  1.361085e+09  Hello,\\n\\nI submitted this to /r/rAskIndia a w...   \n",
      "4  1.551400e+09  Hello r/India.\\n\\nI'm British and would like t...   \n",
      "\n",
      "                     op                                           comments  \n",
      "0         dhavalcoholic   Dear Policy Holder(Dhavalcoholic),\\n \\nWe req...  \n",
      "1       amitkumarthakur   Calm down.\\nGo to the SP office of your town,...  \n",
      "2  FrustratedOCIHopeful   Honestly, she and her supervisor behaved *exa...  \n",
      "3             multubunu                                                     \n",
      "4         PoiHolloi2020   The Discovery of India by J.Nehru.\\n\\nYou wil...  \n"
     ]
    }
   ],
   "source": [
    "reddit = praw.Reddit(client_id='MwhK0qtk4ZqRdw', client_secret='cjytrTxD1OR4KtmEyZRk6wY7tfI', user_agent='flair' ,username='gcgvhjchvt2244')\n",
    "flairs_list = [\"AskIndia\", \"Non-Political\", \"[R]eddiquette\", \"Scheduled\", \"Photography\", \"Science/Technology\", \"Politics\", \"Business/Finance\", \"Policy/Economy\", \"Sports\", \"Food\", \"AMA\"]\n",
    "sub = reddit.subreddit('india')\n",
    "data_dict = {\"flairs\":[], \"titles\":[], \"upvotes\":[], \"id\":[], \"url\":[], \"num_comms\": [], \"created\": [], \"content\":[], \"op\":[], \"comments\":[]}\n",
    "\n",
    "for flair in flairs_list:\n",
    "    posts = sub.search(flair, limit=110)\n",
    "    for post in posts:\n",
    "        data_dict[\"flairs\"].append(flair)\n",
    "        data_dict[\"titles\"].append(post.title)\n",
    "        data_dict[\"upvotes\"].append(post.score)\n",
    "        data_dict[\"id\"].append(post.id)\n",
    "        data_dict[\"url\"].append(post.url)\n",
    "        data_dict[\"num_comms\"].append(post.num_comments)\n",
    "        data_dict[\"created\"].append(post.created)\n",
    "        data_dict[\"content\"].append(post.selftext)\n",
    "        data_dict[\"op\"].append(post.author)\n",
    "\n",
    "        post.comments.replace_more(limit=None)\n",
    "        comment = ''\n",
    "        for top_level_comment in post.comments:\n",
    "            comment += ' ' + top_level_comment.body\n",
    "        data_dict[\"comments\"].append(comment)\n",
    "\n",
    "data_df = pd.DataFrame(data_dict)\n",
    "print(data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Dear Policy Holder(Dhavalcoholic),\\n \\nWe req...\n",
       "1        Calm down.\\nGo to the SP office of your town,...\n",
       "2        Honestly, she and her supervisor behaved *exa...\n",
       "3                                                        \n",
       "4        The Discovery of India by J.Nehru.\\n\\nYou wil...\n",
       "                              ...                        \n",
       "1223     Guys, can someone explain why randia is bashi...\n",
       "1224     I just hope he completely attends the AMA and...\n",
       "1225     Nobody knows the future. We never saw it cumm...\n",
       "1226     1 large popcorn + 1 large cold drink = Rs. 21...\n",
       "1227     There is a context to that statement. \\n\\nPlu...\n",
       "Name: comments, Length: 1228, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_df['titles']+data_df['comments'], data_df['flairs'], random_state= 0)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    " \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    " \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    " \n",
    "# settings that you use for count vectorizer will go here\n",
    "tfidf_vectorizer=TfidfVectorizer(use_idf=True,stop_words ='english')\n",
    " \n",
    "# just send in all your docs here\n",
    "tfidf_vectorizer_vectors=tfidf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC().fit(tfidf_vectorizer_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 1 features per sample; expecting 27085",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-66febc2728c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cvbnm,'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \"\"\"\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 270\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 1 features per sample; expecting 27085"
     ]
    }
   ],
   "source": [
    "print(clf.predict(tfidf_vectorizer.fit_transform(['cvbnm,']).toarray()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.44      0.46      0.45        26\n",
      "     Non-Political       0.44      0.46      0.45        26\n",
      "     [R]eddiquette       0.44      0.46      0.45        26\n",
      "         Scheduled       0.44      0.46      0.45        26\n",
      "       Photography       0.44      0.46      0.45        26\n",
      "Science/Technology       0.44      0.46      0.45        26\n",
      "          Politics       0.44      0.46      0.45        26\n",
      "  Business/Finance       0.44      0.46      0.45        26\n",
      "    Policy/Economy       0.44      0.46      0.45        26\n",
      "            Sports       0.44      0.46      0.45        26\n",
      "              Food       0.44      0.46      0.45        26\n",
      "               AMA       0.44      0.46      0.45        26\n",
      "\n",
      "          accuracy                           0.72     33494\n",
      "         macro avg       0.75      0.71      0.72     33494\n",
      "      weighted avg       0.75      0.72      0.72     33494\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/classification.py:1870: UserWarning: labels size, 1228, does not match size of target_names, 12\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_pred = clf.predict(count_vect.transform(X_test))\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test,y_pred, labels= data_df.flairs, target_names=data_df['flairs'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Need feedback for Insurance Policy that I took. (x-post AskIndia) Dear Policy Holder(Dhavalcoholic),\\n \\nWe request you to help us with your contact details to assist you.\\n\\nAlternatively, you may also post your request along with your policy details on  http://www.iciciprulife.com/ipru/GrievanceRedStep.jsp?step=2\\nRequest you to quote the reference number 101346 whilst sharing the details. Post receipt of the requirement, our representative will get in touch with you within 48 hours.\\n\\nRegards,\\nICICI Prudential Life Insurance'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_df['titles']+data_df['comments'])[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
